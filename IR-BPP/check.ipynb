{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7dd7edf",
   "metadata": {},
   "source": [
    "To view the sequence of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d313fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ test_sequence.pt: [73, 149, 166, 138, 39, 91, 32, 148, 94, 71, 23, 1, 41, 124, 37, 28, 121, 113, 87, 173, 170, 52, 123, 38, 142, 126]\n",
      "üîπ id2shape.pt keys: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "dic = torch.load('./dataset/kitchen/id2shape.pt')\n",
    "seq = torch.load('./dataset/kitchen/test_sequence.pt')\n",
    "\n",
    "print(\"test_sequence.pt:\", seq[2])\n",
    "print(\"id2shape.pt keys:\", list(dic.keys())[:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2949f6a8",
   "metadata": {},
   "source": [
    "To generate a new sequence of items to be packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ca7cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created 1000 sequences, each with 26 unique shape IDs.\n",
      "Saved to: ./dataset/kitchen/test_sequence.pt\n",
      "Shape ID range: 0 to 179\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Load the shape dictionary\n",
    "dic = torch.load('./dataset/kitchen/id2shape.pt')\n",
    "num_shapes = len(dic)\n",
    "\n",
    "# Ensure you have at least 30 shapes\n",
    "assert num_shapes >= 26, f\"Need at least 30 shapes, but found only {num_shapes}\"\n",
    "\n",
    "# Where to save\n",
    "save_path = './dataset/kitchen/test_sequence.pt'\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "# Generate 500 sequences, each with 30 unique shape IDs\n",
    "sequences = []\n",
    "for i in range(1000):\n",
    "    seq = torch.randperm(num_shapes)[:26]  # 30 unique random IDs\n",
    "    sequences.append(seq.tolist())\n",
    "\n",
    "# Save all sequences\n",
    "torch.save(sequences, save_path)\n",
    "\n",
    "print(f\"‚úÖ Created {len(sequences)} sequences, each with 25 unique shape IDs.\")\n",
    "print(f\"Saved to: {save_path}\")\n",
    "print(f\"Shape ID range: 0 to {num_shapes - 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febb7d65",
   "metadata": {},
   "source": [
    "Online packing to generate a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b69ecbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pybullet build time: Dec  1 2021 18:33:04\n",
      "first hierachical False\n",
      "                          Options\n",
      "                          hidden_size: 128\n",
      "                          noisy_std: 0.5\n",
      "                          atoms: 31\n",
      "                          V_min: -1\n",
      "                          V_max: 8\n",
      "                          target_update: 1000\n",
      "                          multi_step: 3\n",
      "                          discount: 0.99\n",
      "                          reward_clip: 0\n",
      "                          learning_rate: 6.25e-05\n",
      "                          batch_size: 64\n",
      "                          norm_clip: 10\n",
      "                          memory_capacity: 100000\n",
      "                          replay_frequency: 4\n",
      "                          priority_exponent: 0.5\n",
      "                          priority_weight: 1.0\n",
      "                          id: default\n",
      "                          seed: 123\n",
      "                          disable_cuda: False\n",
      "                          T_max: 50000000\n",
      "                          max_episode_length: 108000\n",
      "                          history_length: 1\n",
      "                          architecture: canonical\n",
      "                          load_model: False\n",
      "                          learn_start: 500\n",
      "                          evaluation_interval: 100000\n",
      "                          evaluation_episodes_training: 100\n",
      "                          evaluation_size: 500\n",
      "                          render: False\n",
      "                          enable_cudnn: False\n",
      "                          checkpoint_interval: 10000\n",
      "                          save_interval: 1000\n",
      "                          model_save_path: ./logs/experiment\n",
      "                          disable_bzip_memory: False\n",
      "                          print_log_interval: 10\n",
      "                          adam_eps: 0.00015\n",
      "                          envName: Physics-v0\n",
      "                          dataset: kitchen\n",
      "                          device: 0\n",
      "                          custom: blockoutexp\n",
      "                          hierachical: False\n",
      "                          bufferSize: 1\n",
      "                          num_processes: 1\n",
      "                          distributed: False\n",
      "                          samplePointsNum: 1024\n",
      "                          selectedAction: 500\n",
      "                          maxBatch: 2\n",
      "                          visual: True\n",
      "                          resolutionA: 0.02\n",
      "                          resolutionH: 0.01\n",
      "                          resolutionZ: 0.01\n",
      "                          resolutionRot: 8\n",
      "                          locmodel: ./models/kitchen_online.pt\n",
      "                          ordmodel: None\n",
      "                          only_simulate_current: False\n",
      "                          non_blocking: False\n",
      "                          time_limit: 0.01\n",
      "                          evaluate: True\n",
      "                          evaluation_episodes_test: 30\n",
      "                          inference: None\n",
      "Load objects from: ./dataset/kitchen/shape_vhacd\n",
      "first hierachical False\n",
      "                          Options\n",
      "                          hidden_size: 128\n",
      "                          noisy_std: 0.5\n",
      "                          atoms: 31\n",
      "                          V_min: -1\n",
      "                          V_max: 8\n",
      "                          target_update: 1000\n",
      "                          multi_step: 3\n",
      "                          discount: 0.99\n",
      "                          reward_clip: 0\n",
      "                          learning_rate: 6.25e-05\n",
      "                          batch_size: 64\n",
      "                          norm_clip: 10\n",
      "                          memory_capacity: 100000\n",
      "                          replay_frequency: 4\n",
      "                          priority_exponent: 0.5\n",
      "                          priority_weight: 1.0\n",
      "                          id: default\n",
      "                          seed: 123\n",
      "                          disable_cuda: False\n",
      "                          T_max: 50000000\n",
      "                          max_episode_length: 108000\n",
      "                          history_length: 1\n",
      "                          architecture: canonical\n",
      "                          load_model: False\n",
      "                          learn_start: 500\n",
      "                          evaluation_interval: 100000\n",
      "                          evaluation_episodes_training: 100\n",
      "                          evaluation_size: 500\n",
      "                          render: False\n",
      "                          enable_cudnn: False\n",
      "                          checkpoint_interval: 10000\n",
      "                          save_interval: 1000\n",
      "                          model_save_path: ./logs/experiment\n",
      "                          disable_bzip_memory: False\n",
      "                          print_log_interval: 10\n",
      "                          adam_eps: 0.00015\n",
      "                          envName: Physics-v0\n",
      "                          dataset: kitchen\n",
      "                          device: 0\n",
      "                          custom: blockoutexp\n",
      "                          hierachical: False\n",
      "                          bufferSize: 1\n",
      "                          num_processes: 1\n",
      "                          distributed: False\n",
      "                          samplePointsNum: 1024\n",
      "                          selectedAction: 500\n",
      "                          maxBatch: 2\n",
      "                          visual: True\n",
      "                          resolutionA: 0.02\n",
      "                          resolutionH: 0.01\n",
      "                          resolutionZ: 0.01\n",
      "                          resolutionRot: 8\n",
      "                          locmodel: ./models/kitchen_online.pt\n",
      "                          ordmodel: None\n",
      "                          only_simulate_current: False\n",
      "                          non_blocking: False\n",
      "                          time_limit: 0.01\n",
      "                          evaluate: True\n",
      "                          evaluation_episodes_test: 30\n",
      "                          inference: None\n",
      "Load objects from: ./dataset/kitchen/shape_vhacd\n",
      "Load dataset set: ./dataset/kitchen/test_sequence.pt\n",
      "Loading pretrained model: ./models/kitchen_online.pt\n",
      "Load dataset set: ./dataset/kitchen/test_sequence.pt\n",
      "Evaluation Start\n",
      "üöÄ Starting new episode | Bin 1/3 | Size: [0.34 0.34 0.18]\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=2\n",
      "argv[0] = --unused\n",
      "argv[1] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "MESA: error: ZINK: failed to choose pdev\n",
      "glx: failed to create drisw screen\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=Microsoft Corporation\n",
      "GL_RENDERER=D3D12 (NVIDIA GeForce GTX 1660 Ti)\n",
      "GL_VERSION=4.6 (Core Profile) Mesa 24.0.9-0ubuntu0.3\n",
      "GL_SHADING_LANGUAGE_VERSION=4.60\n",
      "pthread_getconcurrency()=0\n",
      "Version = 4.6 (Core Profile) Mesa 24.0.9-0ubuntu0.3\n",
      "Vendor = Microsoft Corporation\n",
      "Renderer = D3D12 (NVIDIA GeForce GTX 1660 Ti)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n",
      "b3Printf: PyBullet: Constraint Solver: MLCP + PGS\n",
      "\n",
      "switched solver\n",
      "ven = Microsoft Corporation\n",
      "ven = Microsoft Corporation\n",
      "\n",
      "üì¶ Bin 1/3\n",
      "   Size: [0.34 0.34 0.18]\n",
      "   Bin volume: 0.021\n",
      "   Packed volume: 0.006\n",
      "   Utilization: 27.36%\n",
      "\n",
      "# items packed: 20\n",
      "Packed items:\n",
      " - 129=concave/modelNet_bowl_0076_0.obj at [0.178 0.    0.   ]\n",
      " - 127=concave/shapeNet_bowl_10__3f6a6718d729b77bed2eab6efdeec5f8_0.obj at [0.18 0.18 0.  ]\n",
      " - 116=concave/modelNet_bowl_0011_0.obj at [0.177 0.    0.041]\n",
      " - 123=concave/modelNet_bowl_0027_0.obj at [0.175 0.004 0.083]\n",
      " - 118=concave/modelNet_bowl_0002_0.obj at [0.18  0.174 0.006]\n",
      " - 154=concave/shapeNet_bowl_67__446583d7bf857dced5cb6d178687b980_0.obj at [0.18  0.176 0.029]\n",
      " - 151=concave/shapeNet_bowl_86__4cf18594e8851a3d3a5e6305a3a7adee_0.obj at [ 0.172 -0.     0.135]\n",
      " - 161=board/board_0.obj at [0.001 0.2   0.   ]\n",
      " - 140=concave/shapeNet_bowl_65__c8a4719150446e84664b3b9b23ddfcbc_0.obj at [0.001 0.    0.   ]\n",
      " - 150=concave/shapeNet_mug_54__b46e89995f4f9cc5161e440f04bd2a2_0.obj at [0.2   0.148 0.078]\n",
      " - 167=board/board_5.obj at [0.001 0.135 0.034]\n",
      " - 65=objects/063-a_marbles_4.obj at [0.146 0.133 0.001]\n",
      " - 72=objects/gd_can_poisson_016_scaled.obj.smoothed_0.obj at [0.093 0.266 0.038]\n",
      " - 34=objects/gd_mushroom_poisson_003_scaled.obj.smoothed_2.obj at [0.219 0.204 0.115]\n",
      " - 8=objects/gd_mushroom_poisson_004_scaled.obj.smoothed_1.obj at [0.156 0.137 0.093]\n",
      " - 84=objects/bigbird_campbells_chicken_noodle_soup_scaled.obj.smoothed_1.obj at [0.001 0.227 0.06 ]\n",
      " - 91=objects/gd_can_poisson_018_scaled.obj.smoothed_1.obj at [0.031 0.139 0.054]\n",
      " - 38=objects/gd_camera_poisson_010_scaled.obj.smoothed_3.obj at [0.096 0.    0.046]\n",
      " - 81=objects/gd_light_bulb_poisson_010_scaled.obj.smoothed_0.obj at [0.126 0.208 0.117]\n",
      " - 64=objects/063-a_marbles_3.obj at [0.024 0.02  0.019]\n",
      "\n",
      " Reached item limit (25)\n",
      "... Needs repacking. Low utilization\n",
      "\n",
      "üì¶ Bin 2/3\n",
      "   Size: [0.34 0.34 0.18]\n",
      "   Bin volume: 0.021\n",
      "   Packed volume: 0.002\n",
      "   Utilization: 8.49%\n",
      "\n",
      "# items packed: 5\n",
      "Packed items:\n",
      " - 46=objects/kit_ChoppedTomatoes_scaled.obj.smoothed_0.obj at [0.26  0.26  0.001]\n",
      " - 79=objects/kit_BakingVanilla_scaled.obj.smoothed_1.obj at [0.26  0.16  0.001]\n",
      " - 56=objects/kit_OrangeMarmelade_scaled.obj.smoothed_1.obj at [0.18  0.24  0.001]\n",
      " - 99=objects/005_tomato_soup_can_1.obj at [0.16  0.16  0.001]\n",
      " - 20=objects/gd_can_poisson_019_scaled.obj.smoothed_1.obj at [0.22  0.182 0.071]\n",
      "‚ôªÔ∏è  Repacking 5 items into Bin 3...\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 107, in <module>\n",
      "    main(args)\n",
      "  File \"main.py\", line 98, in main\n",
      "    test(args, dqn, True,  timeStr)  # Test\n",
      "  File \"/home/bakirkhon/Thesis_irregular/IR-BPP/tools.py\", line 320, in test\n",
      "    state, reward, done, _ = env.step(action.item())  # Step\n",
      "  File \"/home/bakirkhon/Thesis_irregular/IR-BPP/environment/physics0/binPhy.py\", line 727, in step\n",
      "    angularTol = 0.01)\n",
      "  File \"/home/bakirkhon/Thesis_irregular/IR-BPP/environment/physics0/Interface.py\", line 303, in simulateToQuasistatic\n",
      "    p.stepSimulation()\n",
      "KeyboardInterrupt\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "! python main.py --evaluate --evaluation-episodes-test 30 --locmodel ./models/kitchen_online.pt --device 0 --dataset kitchen --custom blockoutexp --bufferSize 1  --num_processes 1 --samplePointsNum 1024 --selectedAction 500 --resolutionA 0.02 --resolutionH 0.01 --visual #--inference True "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d14be06",
   "metadata": {},
   "source": [
    "Length of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a42ddfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "pred = torch.load(\"/home/bakirkhon/Thesis/3D-bin-packing-master/dataset/training_dataset_irregular.pt\")\n",
    "print(len(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beec8270",
   "metadata": {},
   "source": [
    "Online predicted packing (inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a9a1d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pybullet build time: Dec  1 2021 18:33:04\n",
      "first hierachical False\n",
      "                          Options\n",
      "                          hidden_size: 128\n",
      "                          noisy_std: 0.5\n",
      "                          atoms: 31\n",
      "                          V_min: -1\n",
      "                          V_max: 8\n",
      "                          target_update: 1000\n",
      "                          multi_step: 3\n",
      "                          discount: 0.99\n",
      "                          reward_clip: 0\n",
      "                          learning_rate: 6.25e-05\n",
      "                          batch_size: 64\n",
      "                          norm_clip: 10\n",
      "                          memory_capacity: 100000\n",
      "                          replay_frequency: 4\n",
      "                          priority_exponent: 0.5\n",
      "                          priority_weight: 1.0\n",
      "                          id: default\n",
      "                          seed: 123\n",
      "                          disable_cuda: False\n",
      "                          T_max: 50000000\n",
      "                          max_episode_length: 108000\n",
      "                          history_length: 1\n",
      "                          architecture: canonical\n",
      "                          load_model: False\n",
      "                          learn_start: 500\n",
      "                          evaluation_interval: 100000\n",
      "                          evaluation_episodes_training: 100\n",
      "                          evaluation_size: 500\n",
      "                          render: False\n",
      "                          enable_cudnn: False\n",
      "                          checkpoint_interval: 10000\n",
      "                          save_interval: 1000\n",
      "                          model_save_path: ./logs/experiment\n",
      "                          disable_bzip_memory: False\n",
      "                          print_log_interval: 10\n",
      "                          adam_eps: 0.00015\n",
      "                          envName: Physics-v0\n",
      "                          dataset: kitchen\n",
      "                          device: 0\n",
      "                          custom: blockoutexp\n",
      "                          hierachical: False\n",
      "                          bufferSize: 1\n",
      "                          num_processes: 1\n",
      "                          distributed: False\n",
      "                          samplePointsNum: 1024\n",
      "                          selectedAction: 500\n",
      "                          maxBatch: 2\n",
      "                          visual: True\n",
      "                          resolutionA: 0.02\n",
      "                          resolutionH: 0.01\n",
      "                          resolutionZ: 0.01\n",
      "                          resolutionRot: 8\n",
      "                          locmodel: ./models/kitchen_online.pt\n",
      "                          ordmodel: None\n",
      "                          only_simulate_current: False\n",
      "                          non_blocking: False\n",
      "                          time_limit: 0.01\n",
      "                          evaluate: True\n",
      "                          evaluation_episodes_test: 1\n",
      "                          inference: True\n",
      "Load objects from: ./dataset/kitchen/shape_vhacd\n",
      "first hierachical False\n",
      "                          Options\n",
      "                          hidden_size: 128\n",
      "                          noisy_std: 0.5\n",
      "                          atoms: 31\n",
      "                          V_min: -1\n",
      "                          V_max: 8\n",
      "                          target_update: 1000\n",
      "                          multi_step: 3\n",
      "                          discount: 0.99\n",
      "                          reward_clip: 0\n",
      "                          learning_rate: 6.25e-05\n",
      "                          batch_size: 64\n",
      "                          norm_clip: 10\n",
      "                          memory_capacity: 100000\n",
      "                          replay_frequency: 4\n",
      "                          priority_exponent: 0.5\n",
      "                          priority_weight: 1.0\n",
      "                          id: default\n",
      "                          seed: 123\n",
      "                          disable_cuda: False\n",
      "                          T_max: 50000000\n",
      "                          max_episode_length: 108000\n",
      "                          history_length: 1\n",
      "                          architecture: canonical\n",
      "                          load_model: False\n",
      "                          learn_start: 500\n",
      "                          evaluation_interval: 100000\n",
      "                          evaluation_episodes_training: 100\n",
      "                          evaluation_size: 500\n",
      "                          render: False\n",
      "                          enable_cudnn: False\n",
      "                          checkpoint_interval: 10000\n",
      "                          save_interval: 1000\n",
      "                          model_save_path: ./logs/experiment\n",
      "                          disable_bzip_memory: False\n",
      "                          print_log_interval: 10\n",
      "                          adam_eps: 0.00015\n",
      "                          envName: Physics-v0\n",
      "                          dataset: kitchen\n",
      "                          device: 0\n",
      "                          custom: blockoutexp\n",
      "                          hierachical: False\n",
      "                          bufferSize: 1\n",
      "                          num_processes: 1\n",
      "                          distributed: False\n",
      "                          samplePointsNum: 1024\n",
      "                          selectedAction: 500\n",
      "                          maxBatch: 2\n",
      "                          visual: True\n",
      "                          resolutionA: 0.02\n",
      "                          resolutionH: 0.01\n",
      "                          resolutionZ: 0.01\n",
      "                          resolutionRot: 8\n",
      "                          locmodel: ./models/kitchen_online.pt\n",
      "                          ordmodel: None\n",
      "                          only_simulate_current: False\n",
      "                          non_blocking: False\n",
      "                          time_limit: 0.01\n",
      "                          evaluate: True\n",
      "                          evaluation_episodes_test: 1\n",
      "                          inference: True\n",
      "Load objects from: ./dataset/kitchen/shape_vhacd\n",
      "before: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16], [None], [13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24], [None]]\n",
      "after: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16], [None], [13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24], [None]]\n",
      "cleaned [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16], [13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24]]\n",
      "FixedListCreator: loading ./dataset/kitchen/test_sequence.pt\n",
      "Loading pretrained model: ./models/kitchen_online.pt\n",
      "before: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16], [None], [13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24], [None]]\n",
      "after: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16], [None], [13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24], [None]]\n",
      "cleaned [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16], [13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24]]\n",
      "FixedListCreator: loading ./dataset/kitchen/test_sequence.pt\n",
      "Evaluation Start\n",
      "sorted traj: [145, 106, 107, 116, 155, 151, 172, 171, 161, 175, 120, 137, 167, 39, 49, 31, 63, 22, 45, 103, 59, 78, 25, 101, 46, 85, 40, 29, 90, 48, 16]\n",
      "\n",
      "üì¶ Bin 1: fixed indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16]\n",
      "Retrieved items: [145, 106, 107, 116, 155, 151, 172, 171, 161, 175, 120, 137, 167, 63]\n",
      "üöÄ Starting new episode | Bin 1/2 | Size: [0.34 0.34 0.18]\n",
      "Inference mode is active\n",
      "\n",
      "üìå Predicted packing plan:\n",
      "\n",
      "Bin node 25:\n",
      "  Bin 1: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16]\n",
      "  Bin 2: [None]\n",
      "\n",
      "Bin node 26:\n",
      "  Bin 1: [13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "  Bin 2: []\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=2\n",
      "argv[0] = --unused\n",
      "argv[1] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "MESA: error: ZINK: failed to choose pdev\n",
      "glx: failed to create drisw screen\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=Microsoft Corporation\n",
      "GL_RENDERER=D3D12 (NVIDIA GeForce GTX 1660 Ti)\n",
      "GL_VERSION=4.6 (Core Profile) Mesa 24.0.9-0ubuntu0.3\n",
      "GL_SHADING_LANGUAGE_VERSION=4.60\n",
      "pthread_getconcurrency()=0\n",
      "Version = 4.6 (Core Profile) Mesa 24.0.9-0ubuntu0.3\n",
      "Vendor = Microsoft Corporation\n",
      "Renderer = D3D12 (NVIDIA GeForce GTX 1660 Ti)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n",
      "b3Printf: PyBullet: Constraint Solver: MLCP + PGS\n",
      "\n",
      "switched solver\n",
      "ven = Microsoft Corporation\n",
      "ven = Microsoft Corporation\n",
      "\n",
      "üì¶ Bin 1/2\n",
      "   Size: [0.34 0.34 0.18]\n",
      "   Bin volume: 0.021\n",
      "   Packed volume: 0.006\n",
      "   Utilization: 27.07%\n",
      "\n",
      "# items packed: 13\n",
      "Packed items:\n",
      " - 145=concave/modelNet_cup_0083_0.obj at [0.18  0.001 0.   ]\n",
      " - 106=concave/shapeNet_bowl_109__5563324c9902f243a2c59a4d90e63212_0.obj at [0.18  0.    0.065]\n",
      " - 107=concave/shapeNet_bowl_73__a593e8863200fdb0664b3b9b23ddfcbc_0.obj at [0.18  0.    0.079]\n",
      " - 116=concave/modelNet_bowl_0011_0.obj at [0.178 0.004 0.118]\n",
      " - 155=concave/shapeNet_bowl_130__a73d531b90965199e5f6d587dbc348b5_0.obj at [0.18  0.179 0.   ]\n",
      " - 151=concave/shapeNet_bowl_86__4cf18594e8851a3d3a5e6305a3a7adee_0.obj at [0.18  0.188 0.03 ]\n",
      " - 172=board/board_2.obj at [0.02  0.18  0.001]\n",
      " - 171=board/board_3.obj at [0.001 0.18  0.04 ]\n",
      " - 161=board/board_0.obj at [0.001 0.001 0.001]\n",
      " - 175=board/board_6.obj at [0.001 0.18  0.068]\n",
      " - 120=concave/modelNet_cup_0012_0.obj at [0.179 0.197 0.07 ]\n",
      " - 137=concave/modelNet_cup_0008_0.obj at [0.001 0.001 0.036]\n",
      " - 167=board/board_5.obj at [0.001 0.16  0.095]\n",
      "error: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16], [13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24]]\n",
      "error: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16]\n",
      "\n",
      "‚ùó Items that FAILED to pack in bin 1: [16]\n",
      "sorted traj: [145, 106, 107, 116, 155, 151, 172, 171, 161, 175, 120, 137, 167, 39, 49, 31, 63, 22, 45, 103, 59, 78, 25, 101, 46, 85, 40, 29, 90, 48, 16]\n",
      "\n",
      "üì¶ Bin 2: fixed indices = [16, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "Retrieved items: [63, 39, 49, 31, 22, 45, 103, 59, 78, 25, 101, 46]\n",
      "\n",
      "üì¶ Bin 2/2\n",
      "   Size: [0.26 0.26 0.18]\n",
      "   Bin volume: 0.012\n",
      "   Packed volume: 0.004\n",
      "   Utilization: 30.75%\n",
      "\n",
      "# items packed: 4\n",
      "Packed items:\n",
      " - 63=objects/gd_tennis_ball_poisson_000_scaled.obj.smoothed_0.obj at [0.16  0.16  0.001]\n",
      " - 39=objects/gd_rubik_cube_poisson_004_scaled.obj.smoothed_0.obj at [0.14  0.001 0.001]\n",
      " - 49=objects/gd_toilet_paper_poisson_003_scaled.obj.smoothed_0.obj at [0.001 0.14  0.001]\n",
      " - 31=objects/bigbird_campbells_chicken_noodle_soup_scaled.obj.smoothed_0.obj at [0.001 0.001 0.   ]\n",
      "error: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16], [13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24]]\n",
      "error: [16, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "\n",
      "‚ùó Items that FAILED to pack in bin 2: [17, 18, 19, 20, 21, 22, 23, 24]\n",
      "\n",
      "‚úÖ All bins filled for this episode.\n",
      "new_pack_plan [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 14, 15, 16, 18], [10, 12, 17, 19, 20, 21, 22, 23, 24]]\n",
      "FixedListCreator: loading ./dataset/kitchen/test_sequence.pt\n",
      "sorted traj: [121, 153, 113, 147, 111, 169, 151, 177, 136, 178, 122, 120, 167, 39, 5, 62, 2, 68, 66, 11, 89, 105, 20, 78, 32, 46, 79, 21, 51, 75, 76]\n",
      "\n",
      "üì¶ Bin 1: fixed indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 14, 15, 16, 18]\n",
      "Retrieved items: [121, 153, 113, 147, 111, 169, 151, 177, 136, 178, 120, 39, 5, 62, 2, 66]\n",
      "üöÄ Starting new episode | Bin 1/2 | Size: [0.34 0.34 0.18]\n",
      "Inference mode is active\n",
      "\n",
      "üìå Predicted packing plan:\n",
      "\n",
      "Bin node 25:\n",
      "  Bin 1: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 14, 15, 16, 18]\n",
      "  Bin 2: [10, 12, 17, 19, 20, 21, 22, 23, 24]\n",
      "\n",
      "Bin node 26:\n",
      "  Bin 1: [None]\n",
      "  Bin 2: []\n",
      "\n",
      "üì¶ Bin 1/2\n",
      "   Size: [0.34 0.34 0.18]\n",
      "   Bin volume: 0.021\n",
      "   Packed volume: 0.005\n",
      "   Utilization: 26.43%\n",
      "\n",
      "# items packed: 11\n",
      "Packed items:\n",
      " - 121=concave/shapeNet_bowl_169__e3d4d57aea714a88669ff09d7001bab6_0.obj at [0.18  0.001 0.   ]\n",
      " - 153=concave/shapeNet_bowl_17__4fdb0bd89c490108b8c8761d8f1966ba_0.obj at [0.177 0.002 0.053]\n",
      " - 113=concave/shapeNet_bowl_59__95ac294f47fd7d87e0b49f27ced29e3_0.obj at [0.171 0.001 0.107]\n",
      " - 147=concave/modelNet_bowl_0028_0.obj at [0.166 0.004 0.135]\n",
      " - 111=concave/modelNet_bowl_0012_0.obj at [0.181 0.18  0.   ]\n",
      " - 169=board/board_19.obj at [0.02  0.18  0.001]\n",
      " - 151=concave/shapeNet_bowl_86__4cf18594e8851a3d3a5e6305a3a7adee_0.obj at [0.004 0.002 0.005]\n",
      " - 177=board/board_9.obj at [0.001 0.16  0.036]\n",
      " - 136=concave/modelNet_cup_0080_0.obj at [0.001 0.001 0.021]\n",
      " - 178=board/board_14.obj at [0.178 0.2   0.094]\n",
      " - 120=concave/modelNet_cup_0012_0.obj at [0.001 0.16  0.061]\n",
      "error: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 14, 15, 16, 18], [10, 12, 17, 19, 20, 21, 22, 23, 24]]\n",
      "error: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 14, 15, 16, 18]\n",
      "\n",
      "‚ùó Items that FAILED to pack in bin 1: [13, 14, 15, 16, 18]\n",
      "sorted traj: [121, 153, 113, 147, 111, 169, 151, 177, 136, 178, 122, 120, 167, 39, 5, 62, 2, 68, 66, 11, 89, 105, 20, 78, 32, 46, 79, 21, 51, 75, 76]\n",
      "\n",
      "üì¶ Bin 2: fixed indices = [13, 14, 15, 16, 18, 10, 12, 17, 19, 20, 21, 22, 23, 24]\n",
      "Retrieved items: [39, 5, 62, 2, 66, 122, 167, 68, 11, 89, 105, 20, 78, 32]\n",
      "\n",
      "üì¶ Bin 2/2\n",
      "   Size: [0.34 0.34 0.18]\n",
      "   Bin volume: 0.021\n",
      "   Packed volume: 0.007\n",
      "   Utilization: 31.49%\n",
      "\n",
      "# items packed: 14\n",
      "Packed items:\n",
      " - 39=objects/gd_rubik_cube_poisson_004_scaled.obj.smoothed_0.obj at [0.22  0.22  0.001]\n",
      " - 5=objects/gd_light_bulb_poisson_007_scaled.obj.smoothed_0.obj at [0.24  0.1   0.001]\n",
      " - 62=objects/bigbird_hersheys_cocoa_scaled.obj.smoothed_2.obj at [0.155 0.112 0.024]\n",
      " - 2=objects/gd_mushroom_poisson_000_scaled.obj.smoothed_1.obj at [0.24  0.001 0.001]\n",
      " - 66=objects/bigbird_hunts_sauce_scaled.obj.smoothed_0.obj at [0.12  0.001 0.   ]\n",
      " - 122=concave/shapeNet_mug_78__ea127b5b9ba0696967699ff4ba91a25_0.obj at [0.001 0.2   0.001]\n",
      " - 167=board/board_5.obj at [0. 0. 0.]\n",
      " - 68=objects/gd_mushroom_poisson_010_scaled.obj.smoothed_0.obj at [0.163 0.001 0.072]\n",
      " - 11=objects/gd_camera_poisson_010_scaled.obj.smoothed_2.obj at [0.259 0.001 0.089]\n",
      " - 89=objects/bigbird_hersheys_cocoa_scaled.obj.smoothed_1.obj at [0.14  0.223 0.029]\n",
      " - 105=objects/bigbird_progresso_new_england_clam_chowder_scaled.obj.smoothed_0.obj at [0.022 0.221 0.035]\n",
      " - 20=objects/gd_can_poisson_019_scaled.obj.smoothed_1.obj at [0.    0.138 0.009]\n",
      " - 78=objects/gd_mushroom_poisson_005_scaled.obj.smoothed_2.obj at [0.259 0.148 0.094]\n",
      " - 32=objects/gd_rubber_duck_poisson_001_scaled.obj.smoothed_5.obj at [0.002 0.13  0.086]\n",
      "error: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 14, 15, 16, 18], [10, 12, 17, 19, 20, 21, 22, 23, 24]]\n",
      "error: [13, 14, 15, 16, 18, 10, 12, 17, 19, 20, 21, 22, 23, 24]\n",
      "\n",
      "‚ùó Items that FAILED to pack in bin 2: []\n",
      "\n",
      "‚úÖ All bins filled for this episode.\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "! python main.py --evaluate --evaluation-episodes-test 1 --locmodel ./models/kitchen_online.pt --device 0 --dataset kitchen --custom blockoutexp --bufferSize 1  --num_processes 1 --samplePointsNum 1024 --selectedAction 500 --resolutionA 0.02 --resolutionH 0.01 --visual --inference True "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b444c7b",
   "metadata": {},
   "source": [
    "Use this code if you always want to use a dataset of fixed length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c8aefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load file\n",
    "pred = torch.load(\"./dataset/training_dataset_irregular.pt\")\n",
    "\n",
    "# Slice first 500 elements\n",
    "pred_small = pred[:500]\n",
    "\n",
    "# Save to new file\n",
    "torch.save(pred_small, \"./dataset/training_dataset_irregular.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7decc7b2",
   "metadata": {},
   "source": [
    "Allows to see edge predictions in matrix form for the speciific order ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494836a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def format_sublist(subarr):\n",
    "    \"\"\"Convert a small [x y z] NumPy array to a string like [x, y, z].\"\"\"\n",
    "    return \"[\" + \", \".join(f\"{v:g}\" for v in subarr) + \"]\"\n",
    "\n",
    "def format_matrix(m):\n",
    "    \"\"\"Convert a 3D NumPy matrix into nested list string format with commas.\"\"\"\n",
    "    lines = []\n",
    "    for row in m:\n",
    "        row_str = \", \".join(format_sublist(sub) for sub in row)\n",
    "        lines.append(f\"[{row_str}],\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "file_path = '/home/bakirkhon/Thesis_irregular/inference_irregular_predictions.pt'\n",
    "data = torch.load(file_path)\n",
    "# print(data[1][\"E\"].shape)\n",
    "for i in range(len(data)):\n",
    "    print(i)\n",
    "    print(format_matrix(data[i]['E'][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8ed78a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'X': tensor([[1.4331e-01, 1.5857e-01, 1.5942e-01, 5.6302e-04, 1.5542e-01, 1.1124e+00,\n",
      "         1.8786e-01, 2.2845e-02, 2.2724e-02, 2.5279e-02],\n",
      "        [2.5903e-02, 1.5858e-01, 1.5984e-01, 2.1151e-04, 3.2214e-01, 6.1708e+00,\n",
      "         1.9425e-01, 4.1404e-03, 4.1076e-03, 2.5347e-02],\n",
      "        [2.1705e-02, 1.5936e-01, 1.5936e-01, 1.5636e-04, 2.8369e-01, 7.3419e+00,\n",
      "         1.6853e-01, 3.4588e-03, 3.4588e-03, 2.5394e-02],\n",
      "        [4.3914e-02, 1.5902e-01, 1.5902e-01, 2.5592e-04, 2.3046e-01, 3.6212e+00,\n",
      "         2.0465e-01, 6.9833e-03, 6.9832e-03, 2.5288e-02],\n",
      "        [4.9480e-02, 1.5516e-01, 1.5516e-01, 1.8194e-04, 1.5274e-01, 3.1358e+00,\n",
      "         1.8238e-01, 7.6773e-03, 7.6773e-03, 2.4074e-02],\n",
      "        [3.7836e-02, 1.3400e-01, 1.5864e-01, 8.0432e-04, 1.0000e+00, 4.1930e+00,\n",
      "         6.4683e-01, 6.0024e-03, 5.0700e-03, 2.1258e-02],\n",
      "        [2.5371e-02, 1.3264e-01, 1.4051e-01, 4.7050e-04, 9.9500e-01, 5.5383e+00,\n",
      "         5.7208e-01, 3.5649e-03, 3.3653e-03, 1.8638e-02],\n",
      "        [2.5700e-02, 1.2547e-01, 1.4550e-01, 4.6917e-04, 1.0000e+00, 5.6616e+00,\n",
      "         5.7890e-01, 3.7394e-03, 3.2245e-03, 1.8256e-02],\n",
      "        [2.8856e-02, 1.2826e-01, 1.3884e-01, 5.1389e-04, 1.0000e+00, 4.8116e+00,\n",
      "         6.0797e-01, 4.0066e-03, 3.7012e-03, 1.7808e-02],\n",
      "        [1.1329e-01, 1.2735e-01, 1.4802e-01, 5.7487e-04, 2.6919e-01, 1.3066e+00,\n",
      "         2.1743e-01, 1.6769e-02, 1.4427e-02, 1.8850e-02],\n",
      "        [2.0761e-02, 1.2702e-01, 1.3186e-01, 3.4772e-04, 1.0000e+00, 6.3515e+00,\n",
      "         5.4044e-01, 2.7375e-03, 2.6370e-03, 1.6749e-02],\n",
      "        [9.7791e-02, 9.9432e-02, 1.0241e-01, 5.6365e-04, 5.6606e-01, 1.0472e+00,\n",
      "         6.8224e-01, 1.0014e-02, 9.7235e-03, 1.0182e-02],\n",
      "        [9.7796e-02, 9.8116e-02, 1.0061e-01, 5.2070e-04, 5.3936e-01, 1.0288e+00,\n",
      "         9.8601e-01, 9.8392e-03, 9.5954e-03, 9.8715e-03],\n",
      "        [8.6735e-02, 8.6920e-02, 1.0942e-01, 6.0874e-04, 7.3792e-01, 1.2616e+00,\n",
      "         9.2576e-01, 9.4908e-03, 7.5391e-03, 9.5111e-03],\n",
      "        [8.6212e-02, 9.6551e-02, 9.9808e-02, 3.8415e-04, 4.6239e-01, 1.1577e+00,\n",
      "         7.5146e-01, 8.6046e-03, 8.3238e-03, 9.6366e-03],\n",
      "        [6.9186e-02, 9.7914e-02, 9.8124e-02, 3.2409e-04, 4.8755e-01, 1.4183e+00,\n",
      "         6.7960e-01, 6.7888e-03, 6.7743e-03, 9.6077e-03],\n",
      "        [5.5041e-02, 7.4080e-02, 1.1378e-01, 2.8191e-04, 6.0767e-01, 2.0672e+00,\n",
      "         5.1785e-01, 6.2624e-03, 4.0774e-03, 8.4287e-03],\n",
      "        [7.0568e-02, 9.9036e-02, 9.9850e-02, 3.4310e-04, 4.9166e-01, 1.4149e+00,\n",
      "         4.5459e-01, 7.0463e-03, 6.9888e-03, 9.8888e-03],\n",
      "        [7.0306e-02, 9.8813e-02, 9.9794e-02, 3.4730e-04, 5.0095e-01, 1.4194e+00,\n",
      "         5.2797e-01, 7.0161e-03, 6.9471e-03, 9.8609e-03],\n",
      "        [6.9219e-02, 6.9408e-02, 1.1538e-01, 4.1067e-04, 7.4082e-01, 1.6669e+00,\n",
      "         9.0289e-01, 7.9869e-03, 4.8044e-03, 8.0086e-03],\n",
      "        [5.5499e-02, 7.4840e-02, 1.1340e-01, 2.8602e-04, 6.0726e-01, 2.0433e+00,\n",
      "         4.8410e-01, 6.2934e-03, 4.1535e-03, 8.4867e-03],\n",
      "        [6.2193e-02, 8.6913e-02, 8.7542e-02, 2.0082e-04, 4.2438e-01, 1.4076e+00,\n",
      "         6.4709e-01, 5.4445e-03, 5.4054e-03, 7.6086e-03],\n",
      "        [6.6109e-02, 6.7480e-02, 1.0526e-01, 2.0863e-04, 4.4427e-01, 1.5923e+00,\n",
      "         6.8266e-01, 6.9589e-03, 4.4610e-03, 7.1033e-03],\n",
      "        [7.7349e-02, 7.7563e-02, 7.8690e-02, 2.5178e-04, 5.3332e-01, 1.0173e+00,\n",
      "         9.8663e-01, 6.0866e-03, 5.9994e-03, 6.1035e-03],\n",
      "        [7.0400e-02, 7.1800e-02, 7.7182e-02, 1.3887e-04, 3.5595e-01, 1.0963e+00,\n",
      "         2.6277e-01, 5.4336e-03, 5.0547e-03, 5.5417e-03],\n",
      "        [3.4000e-01, 3.4000e-01, 1.8000e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [2.2000e-01, 2.2000e-01, 1.8000e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]), 'traj': [110, 141, 127, 142, 128, 168, 160, 175, 162, 156, 163, 55, 63, 42, 1, 50, 83, 4, 103, 59, 38, 74, 35, 95, 36, 79, 58, 18, 88, 96, 15]}\n"
     ]
    }
   ],
   "source": [
    "file_path = '/home/bakirkhon/Thesis/3D-bin-packing-master/dataset/inference_dataset_irregular.pt'\n",
    "data = torch.load(file_path)\n",
    "print(data[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irbpp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
